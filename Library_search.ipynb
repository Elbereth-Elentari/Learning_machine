{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Library_search.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "15wPUJu7IAAFZAEqqGxWvWaD5bsQ9sHRI",
      "authorship_tag": "ABX9TyPoBKPhQhXUgyORg/pE4ULj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Elbereth-Elentari/Learning_machine/blob/master/Library_search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnTNe_Tfqunb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "from spacy_langdetect import LanguageDetector\n",
        "import pl_core_news_sm\n",
        "import os\n",
        "import random\n",
        "import string\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.support.ui import Select\n",
        "from selenium .webdriver import ChromeOptions\n",
        "import re"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nstO-mjAcq-T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_conditions():\n",
        "    term = input('What would you like to read about?\\n')\n",
        "    term = term.replace(' ', '+')\n",
        "    min_year = int(input('What is the oldest book you are interested in?\\n'))\n",
        "    min_length = 100\n",
        "    max_length = 700\n",
        "    max_books = int(input('How many books do you want?\\n'))\n",
        "    return term, min_year, min_length, max_length, max_books"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPVduYytc6MV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def next_or_break(driver):\n",
        "    try:\n",
        "        next_button = driver.find_element_by_link_text('Następne>')\n",
        "        next_button.click()\n",
        "        return True\n",
        "    except:\n",
        "        return 'no next'"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buhVvX7kc-K-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Book:\n",
        "    interesting_books = set()\n",
        "    all_authors = set()\n",
        "    authors_to_scrape = set()\n",
        "\n",
        "    def __init__(self):\n",
        "        self.title = ''\n",
        "        self.author = ''\n",
        "        self.publisher = ''\n",
        "        self.year = 0\n",
        "        self.pages = 0\n",
        "        self.WD_signature = ''\n",
        "        self.storage = ''\n",
        "\n",
        "    def get_book_attributes(self, record):\n",
        "        title = record.find_element_by_class_name('title').text\n",
        "        self.title = re.sub(r' / .+', '', title)\n",
        "\n",
        "        try:\n",
        "            self.author = record.find_element_by_class_name('author').text\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        if 'BUW Magazyn' in record.text:\n",
        "            self.storage = 'magazyn'\n",
        "\n",
        "        infos = record.find_elements_by_tag_name('tr')\n",
        "        for info in infos:\n",
        "            if 'Klasyfikacja WD' in info.text:\n",
        "                self.WD_signature = info.find_element_by_tag_name('a').text\n",
        "            elif 'Adres wyd.' in info.text:\n",
        "                publisher_candidates = info.find_elements_by_tag_name('span')\n",
        "                for publisher in publisher_candidates:\n",
        "                    if publisher.get_attribute('class') != 'highlight':\n",
        "                        publisher_with_colon = re.search(r'.+ : ?(.+),?.*(\\d{4})', publisher.text)\n",
        "                        if publisher_with_colon:\n",
        "                            publisher = publisher_with_colon\n",
        "                        else:\n",
        "                            publisher = re.search(r'.+? (.+),?.*(\\d{4})', publisher.text)\n",
        "                        self.publisher = publisher.group(1)\n",
        "                        self.year = int(publisher.group(2))\n",
        "            elif 'Opis fiz.' in info.text:\n",
        "                pages = info.find_element_by_tag_name('span').text\n",
        "                pages = re.sub(r'\\[.+?\\]', '', pages)\n",
        "                self.pages = int(re.search(r'\\d+', pages).group(0))\n",
        "\n",
        "    def check_quality(self, record):\n",
        "        if self.year >= min_year and self.pages >= min_length and self.pages <= max_length:\n",
        "            Book.interesting_books.add(self)\n",
        "            if len(self.author) > 0 and self.author in Book.all_authors:\n",
        "                author = record.find_element_by_class_name('author')\n",
        "                Book.authors_to_scrape.add(author.get_attribute('href'))\n",
        "            elif len(self.author) > 0:\n",
        "                Book.all_authors.add(self.author)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLJaVF-RdEqL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_books(driver, expand_set):\n",
        "    records = driver.find_element_by_class_name('records').find_elements_by_tag_name('li')\n",
        "    for record in records:\n",
        "        too_old = 'not too old'\n",
        "\n",
        "        if ('BUW Wolny Dostęp' in record.text or 'BUW Magazyn' in record.text) and 'Adres wyd.' in record.text and 'Opis fiz.' in record.text:\n",
        "            book = Book()\n",
        "            book.get_book_attributes(record)\n",
        "            if expand_set:\n",
        "                book.check_quality(record)\n",
        "            if book.year < min_year and book.year > 0:\n",
        "                too_old = 'too old'\n",
        "                break\n",
        "    return too_old"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C32UXMTtdIiL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_link_set(driver):\n",
        "    links = set()\n",
        "    while True:\n",
        "        tags_from_page = driver.find_element_by_tag_name('tbody').find_elements_by_tag_name('a')\n",
        "        for tag in tags_from_page:\n",
        "            try:\n",
        "                links.add(tag.get_attribute('href'))\n",
        "            except:\n",
        "                pass\n",
        "        if next_or_break(driver) == 'no next': break\n",
        "    return links"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3yebLdEdNFs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_books_from_links(link_set, expand_set=True):\n",
        "    counter = 1\n",
        "    for link in link_set:\n",
        "        print('Progress:', counter/len(link_set))\n",
        "        driver.get(link)\n",
        "        select = Select(driver.find_element_by_id('search_sort'))\n",
        "        select.select_by_value('5')\n",
        "        too_old = get_books(driver, expand_set)\n",
        "        while too_old == 'not too old':\n",
        "            if next_or_break(driver) == 'no next': break\n",
        "            too_old = get_books(driver, expand_set)\n",
        "        counter += 1\n",
        "    return True"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2gGVGf0dR4Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "90a54b39-0e10-47e0-fae1-b84dadea1f30"
      },
      "source": [
        "term, min_year, min_length, max_length, max_books = get_conditions()\n",
        "\n",
        "options = ChromeOptions()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "prefs = {\"profile.managed_default_content_settings.images\": 2}\n",
        "options.add_experimental_option(\"prefs\", prefs)\n",
        "\n",
        "driver = webdriver.Chrome('chromedriver', options=options)\n",
        "driver.get(f'https://chamo.buw.uw.edu.pl/heading/search?match_1=MUST&field_1=heading&term_1={term}&facet_heading_type=subject&sort=heading')\n",
        "\n",
        "print('Creating initial link set')\n",
        "links = create_link_set(driver)\n",
        "print(f'Scraping the {len(links)} initial links')\n",
        "get_books_from_links(links)\n",
        "print(f'Scraping {len(Book.authors_to_scrape)} interesting authors')\n",
        "get_books_from_links(Book.authors_to_scrape, expand_set=False)\n",
        "driver.close()\n",
        "\n",
        "interesting_books = [{'title':book.title, 'author':book.author, 'publisher':book.publisher, 'year':book.year, 'pages':book.pages, 'WD_signature':book.WD_signature, 'storage':book.storage} for book in Book.interesting_books]\n",
        "\n",
        "reading_list = pd.DataFrame(columns=['title','author', 'WD_signature', 'storage', 'publisher', 'year', 'pages'], data=interesting_books)\n",
        "reading_list = deduplicate_books(reading_list)\n",
        "\n",
        "output_file = f'/content/drive/My Drive/Library_search/data/{term}_reading_list.tsv'\n",
        "reading_list[:min(len(reading_list), max_books)].to_csv(output_file, index=False, sep='\\t')"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "What would you like to read about?\n",
            "spowiedź\n",
            "What is the oldest book you are interested in?\n",
            "1990\n",
            "How many books do you want?\n",
            "500\n",
            "Creating initial link set\n",
            "Scraping the 41 initial links\n",
            "Progress: 0.024390243902439025\n",
            "Progress: 0.04878048780487805\n",
            "Progress: 0.07317073170731707\n",
            "Progress: 0.0975609756097561\n",
            "Progress: 0.12195121951219512\n",
            "Progress: 0.14634146341463414\n",
            "Progress: 0.17073170731707318\n",
            "Progress: 0.1951219512195122\n",
            "Progress: 0.21951219512195122\n",
            "Progress: 0.24390243902439024\n",
            "Progress: 0.2682926829268293\n",
            "Progress: 0.2926829268292683\n",
            "Progress: 0.3170731707317073\n",
            "Progress: 0.34146341463414637\n",
            "Progress: 0.36585365853658536\n",
            "Progress: 0.3902439024390244\n",
            "Progress: 0.4146341463414634\n",
            "Progress: 0.43902439024390244\n",
            "Progress: 0.4634146341463415\n",
            "Progress: 0.4878048780487805\n",
            "Progress: 0.5121951219512195\n",
            "Progress: 0.5365853658536586\n",
            "Progress: 0.5609756097560976\n",
            "Progress: 0.5853658536585366\n",
            "Progress: 0.6097560975609756\n",
            "Progress: 0.6341463414634146\n",
            "Progress: 0.6585365853658537\n",
            "Progress: 0.6829268292682927\n",
            "Progress: 0.7073170731707317\n",
            "Progress: 0.7317073170731707\n",
            "Progress: 0.7560975609756098\n",
            "Progress: 0.7804878048780488\n",
            "Progress: 0.8048780487804879\n",
            "Progress: 0.8292682926829268\n",
            "Progress: 0.8536585365853658\n",
            "Progress: 0.8780487804878049\n",
            "Progress: 0.9024390243902439\n",
            "Progress: 0.926829268292683\n",
            "Progress: 0.9512195121951219\n",
            "Progress: 0.975609756097561\n",
            "Progress: 1.0\n",
            "Scraping 181 interesting authors\n",
            "Progress: 0.0055248618784530384\n",
            "Progress: 0.011049723756906077\n",
            "Progress: 0.016574585635359115\n",
            "Progress: 0.022099447513812154\n",
            "Progress: 0.027624309392265192\n",
            "Progress: 0.03314917127071823\n",
            "Progress: 0.03867403314917127\n",
            "Progress: 0.04419889502762431\n",
            "Progress: 0.049723756906077346\n",
            "Progress: 0.055248618784530384\n",
            "Progress: 0.06077348066298342\n",
            "Progress: 0.06629834254143646\n",
            "Progress: 0.0718232044198895\n",
            "Progress: 0.07734806629834254\n",
            "Progress: 0.08287292817679558\n",
            "Progress: 0.08839779005524862\n",
            "Progress: 0.09392265193370165\n",
            "Progress: 0.09944751381215469\n",
            "Progress: 0.10497237569060773\n",
            "Progress: 0.11049723756906077\n",
            "Progress: 0.11602209944751381\n",
            "Progress: 0.12154696132596685\n",
            "Progress: 0.1270718232044199\n",
            "Progress: 0.13259668508287292\n",
            "Progress: 0.13812154696132597\n",
            "Progress: 0.143646408839779\n",
            "Progress: 0.14917127071823205\n",
            "Progress: 0.15469613259668508\n",
            "Progress: 0.16022099447513813\n",
            "Progress: 0.16574585635359115\n",
            "Progress: 0.1712707182320442\n",
            "Progress: 0.17679558011049723\n",
            "Progress: 0.18232044198895028\n",
            "Progress: 0.1878453038674033\n",
            "Progress: 0.19337016574585636\n",
            "Progress: 0.19889502762430938\n",
            "Progress: 0.20441988950276244\n",
            "Progress: 0.20994475138121546\n",
            "Progress: 0.2154696132596685\n",
            "Progress: 0.22099447513812154\n",
            "Progress: 0.2265193370165746\n",
            "Progress: 0.23204419889502761\n",
            "Progress: 0.23756906077348067\n",
            "Progress: 0.2430939226519337\n",
            "Progress: 0.24861878453038674\n",
            "Progress: 0.2541436464088398\n",
            "Progress: 0.2596685082872928\n",
            "Progress: 0.26519337016574585\n",
            "Progress: 0.27071823204419887\n",
            "Progress: 0.27624309392265195\n",
            "Progress: 0.281767955801105\n",
            "Progress: 0.287292817679558\n",
            "Progress: 0.292817679558011\n",
            "Progress: 0.2983425414364641\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-88-bb8a2bcbaa2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mget_books_from_links\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Scraping {len(Book.authors_to_scrape)} interesting authors'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mget_books_from_links\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthors_to_scrape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-87-7bd8d5373ac0>\u001b[0m in \u001b[0;36mget_books_from_links\u001b[0;34m(link_set, expand_set)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mtoo_old\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'not too old'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnext_or_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'no next'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mtoo_old\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_books\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mcounter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-75-f86657022dbb>\u001b[0m in \u001b[0;36mget_books\u001b[0;34m(driver, expand_set)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'BUW Wolny Dostęp'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'BUW Magazyn'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'Adres wyd.'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'Opis fiz.'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_book_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mexpand_set\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0mbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_quality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-46-96bc1d900197>\u001b[0m in \u001b[0;36mget_book_attributes\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m     38\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                             \u001b[0mpublisher\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'.+? (.+),?.*(\\d{4})'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpublisher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublisher\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpublisher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myear\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpublisher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;34m'Opis fiz.'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0oi5tpfsiwa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def merge_tsvs()\n",
        "  cat = pd.DataFrame()\n",
        "  data_path = '/content/drive/My Drive/Library_search/data/'\n",
        "  for file in os.listdir(data_path):\n",
        "      if file.endswith('.tsv'):\n",
        "          print('Processing', file)\n",
        "          c = pd.read_csv(data_path + file, sep='\\t')\n",
        "          cat = cat.append(c, ignore_index=True)\n",
        "  cat.to_csv(data_path + 'Library_catalogue.tsv', sep='\\t', index=False)\n",
        "  return cat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sn1GbS8sZDK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def detect_language(df):\n",
        "    nlp = spacy.load('en_core_web_sm')\n",
        "    nlp.add_pipe(LanguageDetector(), name='language_detector', last=True)\n",
        "\n",
        "    language = []\n",
        "    for index, doc in enumerate(nlp.pipe(df['title'].values, batch_size=1000)):\n",
        "        if index % 100 == 0:\n",
        "            print('Progress:', index/len(df['title']))\n",
        "        if doc.is_parsed:\n",
        "            if doc._.language['language'] == 'en':\n",
        "                language.append('en')\n",
        "            else:\n",
        "                language.append('pl')\n",
        "        else:\n",
        "            language.append('')\n",
        "\n",
        "    df['language'] = language\n",
        "    for language in df.language.unique():\n",
        "      sample = random.sample(list(df[df['language'] == language].index), 20)\n",
        "      print(f'{language} sample')\n",
        "      for row in df[df.index.isin(sample)].itertuples():\n",
        "          print(row.title)\n",
        "    return df"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1L-X56qmr3cG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def deduplicate_books(df):\n",
        "    df.drop_duplicates(inplace=True)\n",
        "    df.sort_values(by='year', ascending=False, inplace=True)\n",
        "    df.drop_duplicates(subset='title', inplace=True)\n",
        "    return df"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xW44FF_exnQR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(file):\n",
        "    cat = pd.read_csv(file, sep='\\t')\n",
        "    cat = deduplicate_books(cat)\n",
        "    cat = detect_language(cat)\n",
        "    preprocessed_cat = pd.DataFrame()\n",
        "\n",
        "    for lang in ['pl', 'en']:\n",
        "        print(f'Preprocessing {lang}')\n",
        "        if lang == 'en':\n",
        "            nlp = spacy.load('en_core_web_sm')\n",
        "        elif lang == 'pl':\n",
        "            nlp = pl_core_news_sm.load()\n",
        "\n",
        "        df = cat[cat['language'] == lang]\n",
        "        stopwords = nlp.Defaults.stop_words\n",
        "\n",
        "        preprocessed = []\n",
        "        for index, doc in enumerate(nlp.pipe(df['title'].values, batch_size=200)):\n",
        "            if index % 100 == 0:\n",
        "                print('Progress:', index/len(df))\n",
        "            if doc.is_parsed:\n",
        "                tokens = [token.lemma_.lower() for token in doc if (token.text.lower() not in stopwords and token.text not in string.punctuation)]\n",
        "                if len(tokens) > 0:\n",
        "                    preprocessed.append(tokens)\n",
        "                else:\n",
        "                    preprocessed.append('preprocessing_fail')\n",
        "            else:\n",
        "                print('Preprocessing failed')\n",
        "                preprocessed.append('preprocessing_fail')\n",
        "\n",
        "        df['tokens'] = preprocessed\n",
        "        df = df[df['tokens'] != 'preprocessing_fail']\n",
        "        preprocessed_cat = preprocessed_cat.append(df)\n",
        "    return preprocessed_cat"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zngf0Funx1vX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preprocessed_cat = preprocess('/content/drive/My Drive/Library_search/data/Library_catalogue.tsv')\n",
        "preprocessed_cat.to_csv(f'/content/drive/My Drive/Library_search/data/Preprocessed_catalogue.tsv', index=False, sep='\\t')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrkbKsJscN5l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tag = preprocess(f'/content/drive/My Drive/Library_search/data/{term}_reading_list.tsv')\n",
        "tag_en = tag[tag['language'] == 'en']\n",
        "tag_en['tokens'] = tag_en['tokens'].apply(lambda x: x+[term])\n",
        "en = preprocessed_cat[preprocessed_cat['language'] == 'en']\n",
        "for index, row in tag_en.iterrows():\n",
        "    en.drop(en[en['title'] == row['title']].index, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmuk348_17qR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = spacy.load('en_core_web_sm')\n",
        "topic = ' '.join([' '.join(tokens) for tokens in tag_en['tokens']])\n",
        "topic = nlp(topic)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atlxgva82Q6r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "similarity = []\n",
        "for index, doc in enumerate(nlp.pipe(en['title'].values, batch_size=200)):\n",
        "    if index % 100 == 0:\n",
        "        print('Progress:', index/len(en))\n",
        "    if doc.is_parsed:\n",
        "        similarity.append(topic.similarity(doc))\n",
        "    else:\n",
        "        print('Similarity failed')\n",
        "        preprocessed.append('similarity_fail')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x53vqGTd2c-t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "en['similarity'] = similarity\n",
        "en.sort_values(by='similarity', inplace=True, ascending=False)\n",
        "for row in en[:5].itertuples():\n",
        "    print(row.title, row.similarity)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}